{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be34cfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2a9110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a06411/opt/anaconda3/envs/fluentPython/lib/python3.11/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1338b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d021fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/11 23:34:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder.appName('mysql-api')\n",
    "                             .config(\"spark.driver.host\",\"127.0.0.1\") \n",
    "                             .config(\"spark.driver.bindAddress\",\"127.0.0.1\")\n",
    "                             .config(\"spark.jars\",\"{}/mysql-connector-j-8.0.33/mysql-connector-j-8.0.33.jar\".format(os.getcwd()))\n",
    "                             .config(\"spark.driver.extraClassPath\",\"{}/mysql-connector-j-8.0.33/mysql-connector-j-8.0.33.jar\".format(os.getcwd()))\n",
    "                             .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5dd25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://127.0.0.1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>mysql-api</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x137779390>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987d6e44",
   "metadata": {},
   "source": [
    "## 테이블 단위로 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47906112",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_df = (spark.read.format(\"jdbc\")\n",
    "            .option(\"url\", \"jdbc:mysql://localhost:3306/sakila\")\n",
    "            .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\n",
    "            .option(\"dbtable\", \"actor\") \n",
    "            .option(\"user\", \"root\")\n",
    "            .option(\"inferSchema\", \"true\")\n",
    "            .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2b1a1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- actor_id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- last_update: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actor_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97de2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e06835a8",
   "metadata": {},
   "source": [
    "## 쿼리로 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b2a1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tables = \"select * from actor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be9e75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actor = (spark.read .format(\"jdbc\") \n",
    "    .option(\"url\", \"jdbc:mysql://localhost:3306/sakila\") \n",
    "    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\n",
    "    .option(\"query\", query_tables) \n",
    "    .option(\"user\", \"root\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2db1e12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actor.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f15afe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------+-------------------+\n",
      "|actor_id|first_name|   last_name|        last_update|\n",
      "+--------+----------+------------+-------------------+\n",
      "|       1|  PENELOPE|     GUINESS|2006-02-15 04:34:33|\n",
      "|       2|      NICK|    WAHLBERG|2006-02-15 04:34:33|\n",
      "|       3|        ED|       CHASE|2006-02-15 04:34:33|\n",
      "|       4|  JENNIFER|       DAVIS|2006-02-15 04:34:33|\n",
      "|       5|    JOHNNY|LOLLOBRIGIDA|2006-02-15 04:34:33|\n",
      "|       6|     BETTE|   NICHOLSON|2006-02-15 04:34:33|\n",
      "|       7|     GRACE|      MOSTEL|2006-02-15 04:34:33|\n",
      "|       8|   MATTHEW|   JOHANSSON|2006-02-15 04:34:33|\n",
      "|       9|       JOE|       SWANK|2006-02-15 04:34:33|\n",
      "|      10| CHRISTIAN|       GABLE|2006-02-15 04:34:33|\n",
      "|      11|      ZERO|        CAGE|2006-02-15 04:34:33|\n",
      "|      12|      KARL|       BERRY|2006-02-15 04:34:33|\n",
      "|      13|       UMA|        WOOD|2006-02-15 04:34:33|\n",
      "|      14|    VIVIEN|      BERGEN|2006-02-15 04:34:33|\n",
      "|      15|      CUBA|     OLIVIER|2006-02-15 04:34:33|\n",
      "|      16|      FRED|     COSTNER|2006-02-15 04:34:33|\n",
      "|      17|     HELEN|      VOIGHT|2006-02-15 04:34:33|\n",
      "|      18|       DAN|        TORN|2006-02-15 04:34:33|\n",
      "|      19|       BOB|     FAWCETT|2006-02-15 04:34:33|\n",
      "|      20|   LUCILLE|       TRACY|2006-02-15 04:34:33|\n",
      "+--------+----------+------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_actor.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e7251e",
   "metadata": {},
   "source": [
    "## 테이블에 쓰기\n",
    "\n",
    "jdbcUrl = \"jdbc:mysql://<host>:<port>/<database>\"\n",
    "username = \"<username>\"\n",
    "password = \"<password>\"\n",
    "\n",
    "df.write \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .option(\"url\", jdbcUrl) \\\n",
    "  .option(\"user\", username) \\\n",
    "  .option(\"password\", password) \\\n",
    "  .option(\"dbtable\", \"<table>\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .save()\n",
    "   \n",
    "### \n",
    "MYSQL_URL = \"jdbc:mysql://{server}:<port>/{database}?user={username}&password={password}\"\n",
    "df.write.jdbc(MYSQL_URL, table=\"<table_name>\", mode=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1015e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d565882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473428e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
